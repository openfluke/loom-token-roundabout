# loom-token-roundabout
loom-token-roundabout is a playful demo that trains and samples a tiny language model on a looping “roundabout” of forward → backward → accumulate → optimize steps. It builds a fresh BPE tokenizer from your text, runs a compact grid network with gradient accumulation and AdamW updates, and lets you spin out as many tokens as you like.
